#!/bin/bash

set -e  # Exit on any error

# Store project root directory
PROJECT_ROOT="$(pwd)"

# Parse command line arguments (must be before cleanup trap setup)
WAIT_BEFORE_TEARDOWN=false
BUILD_IMAGE=false
while [[ $# -gt 0 ]]; do
  case $1 in
    --wait)
      WAIT_BEFORE_TEARDOWN=true
      shift
      ;;
    --build)
      BUILD_IMAGE=true
      shift
      ;;
    *)
      echo "Unknown option: $1"
      echo "Usage: $0 [--wait] [--build]"
      exit 1
      ;;
  esac
done

# Create temp directory for test execution
TEST_WORKDIR=$(mktemp -d -t easy-db-lab-e2e-XXXXXX)
echo "=== Using temporary work directory: $TEST_WORKDIR ==="

# Cleanup function - asks before removing temp dir unless --wait was specified
cleanup() {
    local exit_code=$?
    if [ "$WAIT_BEFORE_TEARDOWN" != true ]; then
        echo ""
        echo "=== Test work directory: $TEST_WORKDIR ==="
        read -p "Delete temporary work directory? [y/N] " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            echo "=== Cleaning up temp directory ==="
            rm -rf "$TEST_WORKDIR"
        else
            echo "=== Temp directory preserved at: $TEST_WORKDIR ==="
        fi
    else
        echo "=== Temp directory preserved at: $TEST_WORKDIR ==="
    fi
    exit $exit_code
}
trap cleanup EXIT

echo "=== Building project ==="
./gradlew clean test shadowJar installDist :spark-connector-test1:jar

echo "=== Checking version ==="
"$PROJECT_ROOT/bin/easy-db-lab" version

if [ "$BUILD_IMAGE" = true ]; then
  echo "=== Building packer images ==="
  "$PROJECT_ROOT/bin/easy-db-lab" build-image
fi

# Change to temp directory for all easy-db-lab commands that create files
cd "$TEST_WORKDIR"
echo "=== Changed to work directory: $(pwd) ==="

echo "=== Creating IAM managed policies ==="
"$PROJECT_ROOT/bin/set-policies" --group-name EasyDBLabUsers --profile sandbox-admin

echo "=== Initializing cluster ==="
"$PROJECT_ROOT/bin/easy-db-lab" init -c 2 -i c5.2xlarge test --clean --up -s 1 \
  --spark.enable \
  --spark.master.instance.type m5.xlarge \
  --spark.worker.instance.type m5.xlarge \
  --spark.worker.instance.count 2

echo "=== Setting up kubectl access ==="
shopt -s expand_aliases
source env.sh

echo "=== Waiting for K3s cluster to be ready ==="
# Wait up to 60 seconds for nodes to be ready
timeout=60
elapsed=0
while [ $elapsed -lt $timeout ]; do
  if kubectl get nodes &>/dev/null; then
    echo "kubectl connectivity established"
    break
  fi
  echo "Waiting for kubectl to connect... ($elapsed/$timeout seconds)"
  sleep 5
  elapsed=$((elapsed + 5))
done

if [ $elapsed -ge $timeout ]; then
  echo "ERROR: kubectl failed to connect to K3s cluster after $timeout seconds"
  exit 1
fi

echo "=== Verifying K3s cluster nodes ==="
kubectl get nodes

echo "=== Verifying K3s system pods ==="
kubectl get pods -A

echo "=== Waiting for all nodes to be Ready ==="
# Wait for all nodes to reach Ready state
kubectl wait --for=condition=Ready nodes --all --timeout=120s

echo "=== Listing cluster hosts ==="
"$PROJECT_ROOT/bin/easy-db-lab" hosts

echo "=== Listing available Cassandra versions ==="
"$PROJECT_ROOT/bin/easy-db-lab" list

echo "=== Setting Cassandra version to 5.0 ==="
"$PROJECT_ROOT/bin/easy-db-lab" use 5.0

echo "=== Updating configuration ==="
"$PROJECT_ROOT/bin/easy-db-lab" update-config

echo "=== Starting Cassandra ==="
"$PROJECT_ROOT/bin/easy-db-lab" start

echo "=== Stopping Cassandra ==="
"$PROJECT_ROOT/bin/easy-db-lab" stop

echo "=== Waiting for Cassandra to stop ==="
sleep 10

echo "=== Starting Cassandra again ==="
"$PROJECT_ROOT/bin/easy-db-lab" start

echo "=== Restarting Cassandra ==="
"$PROJECT_ROOT/bin/easy-db-lab" restart

echo "=== Testing SSH access and nodetool via env.sh aliases ==="
ssh cassandra0 nodetool status

echo "=== Check Sidecar ==="
ssh cassandra0 "curl http://$("$PROJECT_ROOT/bin/easy-db-lab" ip cassandra0 --private):9043/api/v1/cassandra/schema"

echo "=== Testing exec command (sequential) ==="
"$PROJECT_ROOT/bin/easy-db-lab" exec -t cassandra hostname

echo "=== Testing exec command (parallel) ==="
"$PROJECT_ROOT/bin/easy-db-lab" exec -t cassandra -p uptime

echo "=== Testing exec command (with host filter) ==="
"$PROJECT_ROOT/bin/easy-db-lab" exec -t cassandra --hosts cassandra0,cassandra1 date

echo "=== Running stress test ==="
which ssh
ssh stress0 "bash -l -c 'cassandra-easy-stress run KeyValue -d 10s'"

echo "=== Submitting Spark job to EMR ==="
"$PROJECT_ROOT/bin/easy-db-lab" spark submit \
  --jar "$PROJECT_ROOT/spark-connector-test1/build/libs/spark-connector-test1-12.jar" \
  --main-class com.rustyrazorblade.easydblab.spark.KeyValuePrefixCount \
  --args "$("$PROJECT_ROOT/bin/easy-db-lab" ip cassandra0 --private)" \
  --wait

echo "=== Listing Spark jobs ==="
"$PROJECT_ROOT/bin/easy-db-lab" spark jobs

echo "=== Checking Spark job status (automatically downloads logs) ==="
"$PROJECT_ROOT/bin/easy-db-lab" spark status

echo "=== Downloading all EMR logs (standalone command) ==="
"$PROJECT_ROOT/bin/easy-db-lab" spark logs

if [ "$WAIT_BEFORE_TEARDOWN" = true ]; then
  echo ""
  echo "=== Cluster is ready for inspection ==="
  echo "The cluster is now running and ready to inspect."
  echo "Work directory: $TEST_WORKDIR"
  echo "You can:"
  echo "  - Run: kubectl get nodes"
  echo "  - Run: kubectl get pods -A"
  echo "  - SSH to nodes using the aliases from env.sh"
  echo "  - Test Cassandra connectivity"
  echo ""
  read -p "Press Enter to tear down the cluster and complete the test..."
  echo ""
fi

echo "=== Tearing down cluster ==="
"$PROJECT_ROOT/bin/easy-db-lab" down --yes

echo "=== End-to-end test completed successfully ==="
