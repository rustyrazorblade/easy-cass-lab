#!/bin/bash

set -e  # Exit on any error

# Store project root directory
PROJECT_ROOT="$(pwd)"

# Work directory is the same as project root (no temp directory)
TEST_WORKDIR="$PROJECT_ROOT"

# Prepend bin directory to PATH so easy-db-lab uses this worktree's version
export PATH="$PROJECT_ROOT/bin:$PATH"

# Track current step for resume functionality
CURRENT_STEP=0
CURRENT_STEP_NAME=""

# Parse command line arguments (must be before cleanup trap setup)
WAIT_BEFORE_TEARDOWN=false
BUILD_IMAGE=false
ENABLE_SPARK=false
ENABLE_CASSANDRA=false
ENABLE_CLICKHOUSE=false
ENABLE_OPENSEARCH=false
USE_EBS=false
EXIT_OK=false
LIST_STEPS=false
BREAKPOINTS=""
while [[ $# -gt 0 ]]; do
  case $1 in
    --list-steps|-l)
      LIST_STEPS=true
      shift
      ;;
    --break)
      BREAKPOINTS="$2"
      shift 2
      ;;
    --wait)
      WAIT_BEFORE_TEARDOWN=true
      shift
      ;;
    --build)
      BUILD_IMAGE=true
      shift
      ;;
    --spark)
      ENABLE_SPARK=true
      shift
      ;;
    --cassandra)
      ENABLE_CASSANDRA=true
      shift
      ;;
    --clickhouse)
      ENABLE_CLICKHOUSE=true
      shift
      ;;
    --opensearch)
      ENABLE_OPENSEARCH=true
      shift
      ;;
    --all)
      ENABLE_SPARK=true
      ENABLE_CASSANDRA=true
      ENABLE_CLICKHOUSE=true
      ENABLE_OPENSEARCH=true
      shift
      ;;
    --ebs)
      USE_EBS=true
      shift
      ;;
    *)
      echo "Unknown option: $1"
      echo "Usage: $0 [--list-steps|-l] [--break <steps>] [--wait] [--build] [--spark] [--cassandra] [--clickhouse] [--opensearch] [--all] [--ebs]"
      exit 1
      ;;
  esac
done

# ============================================================================
# Test Step Functions
# ============================================================================

step_build_project() {
    echo "=== Building project ==="
    if [ "$ENABLE_SPARK" = true ]; then
        (cd "$PROJECT_ROOT" && ./gradlew clean test shadowJar installDist :spark-connector-test1:jar)
    else
        (cd "$PROJECT_ROOT" && ./gradlew clean test shadowJar installDist)
    fi
}

step_check_version() {
    echo "=== Checking version ==="
    easy-db-lab version
}

step_build_image() {
    if [ "$BUILD_IMAGE" = true ]; then
        echo "=== Building packer images ==="
        easy-db-lab build-image
    else
        echo "=== Skipping packer image build (use --build to enable) ==="
    fi
}

step_set_policies() {
    echo "=== Creating IAM managed policies ==="
    "$PROJECT_ROOT/bin/set-policies" --group-name EasyDBLabUsers --profile sandbox-admin
}

step_init_cluster() {
    echo "=== Initializing cluster ==="
    local spark_opts=""
    if [ "$ENABLE_SPARK" = true ]; then
        spark_opts="--spark.enable --spark.master.instance.type m5.xlarge --spark.worker.instance.type m5.xlarge --spark.worker.instance.count 2"
        echo "=== Spark provisioning enabled ==="
    fi
    local ebs_opts=""
    if [ "$USE_EBS" = true ]; then
        ebs_opts="--ebs.type gp3 --ebs.size 256"
        echo "=== EBS volumes enabled (gp3, 256GB) ==="
    fi
    easy-db-lab init -c 3 -i c5.2xlarge test --clean --up -s 1 $spark_opts $ebs_opts
}

step_setup_kubectl() {
    echo "=== Setting up kubectl access ==="
    source env.sh
}

step_wait_k3s_ready() {
    echo "=== Waiting for K3s cluster to be ready ==="
    local timeout=60
    local elapsed=0
    while [ $elapsed -lt $timeout ]; do
      if kubectl get nodes &>/dev/null; then
        echo "kubectl connectivity established"
        return 0
      fi
      echo "Waiting for kubectl to connect... ($elapsed/$timeout seconds)"
      sleep 5
      elapsed=$((elapsed + 5))
    done
    echo "ERROR: kubectl failed to connect to K3s cluster after $timeout seconds"
    return 1
}

step_verify_k3s() {
    echo "=== Verifying K3s cluster nodes ==="
    kubectl get nodes

    echo "=== Verifying K3s system pods ==="
    kubectl get pods -A

    echo "=== Waiting for all nodes to be Ready ==="
    kubectl wait --for=condition=Ready nodes --all --timeout=120s
}

step_list_hosts() {
    echo "=== Listing cluster hosts ==="
    easy-db-lab hosts

    echo "=== Status Without Cassandra Version ==="
    easy-db-lab status

    echo "=== Listing available Cassandra versions ==="
    easy-db-lab list
}

step_setup_cassandra() {
    if [ "$ENABLE_CASSANDRA" != true ]; then
        echo "=== Skipping Cassandra setup (use --cassandra to enable) ==="
        return 0
    fi
    echo "=== Setting Cassandra version to 5.0 ==="
    easy-db-lab use 5.0

    echo "=== Updating configuration ==="
    easy-db-lab update-config
}

step_cassandra_start_stop() {
    if [ "$ENABLE_CASSANDRA" != true ]; then
        echo "=== Skipping Cassandra start/stop cycle (use --cassandra to enable) ==="
        return 0
    fi
    echo "=== Starting Cassandra ==="
    easy-db-lab start

    echo "=== Status With Cassandra Running ==="
    easy-db-lab status

    echo "=== Stopping Cassandra ==="
    easy-db-lab stop

    echo "=== Waiting for Cassandra to stop ==="
    sleep 10

    echo "=== Starting Cassandra again ==="
    easy-db-lab start

    echo "=== Restarting Cassandra ==="
    easy-db-lab restart
}

step_test_ssh_nodetool() {
    if [ "$ENABLE_CASSANDRA" != true ]; then
        echo "=== Skipping SSH nodetool test (use --cassandra to enable) ==="
        return 0
    fi
    echo "=== Testing SSH access and nodetool via env.sh aliases ==="
    ssh db0 nodetool status
}

step_check_sidecar() {
    if [ "$ENABLE_CASSANDRA" != true ]; then
        echo "=== Skipping Sidecar check (use --cassandra to enable) ==="
        return 0
    fi
    echo "=== Check Sidecar ==="
    ssh db0 "curl -s http://$(easy-db-lab ip db0 --private):9043/api/v1/cassandra/schema" | jq 'keys'
}

step_test_exec() {
    echo "=== Testing exec command (sequential) ==="
    easy-db-lab exec -t cassandra hostname

    echo "=== Testing exec command (parallel) ==="
    easy-db-lab exec -t cassandra -p uptime

    echo "=== Testing exec command (with host filter) ==="
    easy-db-lab exec -t cassandra --hosts db0,db1 date
}

step_stress_test() {
    if [ "$ENABLE_CASSANDRA" != true ]; then
        echo "=== Skipping stress test (use --cassandra to enable) ==="
        return 0
    fi
    echo "=== Running stress test ==="
    ssh app0 "bash -l -c 'cassandra-easy-stress run KeyValue -d 10s'"
}

step_registry_push_pull() {
    echo "=== Testing private registry push/pull over HTTPS ==="

    # Get registry address (private IP - kubectl uses SSH tunnel from env.sh)
    local registry=$(easy-db-lab ip control0 --private):5000

    echo "=== Registry address: $registry ==="

    # Pull busybox locally, tag for private registry, and push
    echo "=== Pulling busybox and pushing to private registry ==="
    docker pull busybox:latest
    docker tag busybox:latest "${registry}/busybox:e2e"
    docker push "${registry}/busybox:e2e"

    # Deploy a pod that pulls from the private registry
    echo "=== Deploying test pod from private registry ==="
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: registry-test
  namespace: default
spec:
  restartPolicy: Never
  containers:
  - name: test
    image: ${registry}/busybox:e2e
    command: ["echo", "Registry HTTPS test successful!"]
EOF

    # Wait for pod to complete
    echo "=== Waiting for test pod to complete ==="
    kubectl wait --for=condition=Ready pod/registry-test --timeout=60s || true
    kubectl wait --for=jsonpath='{.status.phase}'=Succeeded pod/registry-test --timeout=60s

    # Show logs
    echo "=== Test pod logs ==="
    kubectl logs registry-test

    # Cleanup
    echo "=== Cleaning up test pod ==="
    kubectl delete pod registry-test
}

step_stress_k8s() {
    if [ "$ENABLE_CASSANDRA" != true ]; then
        echo "=== Skipping stress K8s test (use --cassandra to enable) ==="
        return 0
    fi
    echo "=== Starting stress job on K8s ==="
    easy-db-lab cassandra stress run --name e2e-test -- KeyValue -d 30s

    echo "=== Checking stress job status ==="
    easy-db-lab cassandra stress status

    echo "=== Waiting for stress job to complete ==="
    local timeout=120
    local elapsed=0
    while [ $elapsed -lt $timeout ]; do
        local status=$(kubectl get jobs -l app.kubernetes.io/name=cassandra-stress -o jsonpath='{.items[0].status.succeeded}' 2>/dev/null || echo "")
        if [ "$status" = "1" ]; then
            echo "Stress job completed successfully"
            break
        fi
        echo "Waiting for stress job to complete... ($elapsed/$timeout seconds)"
        sleep 10
        elapsed=$((elapsed + 10))
    done

    echo "=== Viewing stress job logs ==="
    # Get the job name that we just created (most recent)
    local job_name=$(kubectl get jobs -l app.kubernetes.io/name=cassandra-stress --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1].metadata.name}')
    if [ -n "$job_name" ]; then
        easy-db-lab cassandra stress logs "$job_name" --tail 50
    fi

    echo "=== Stopping stress job ==="
    easy-db-lab cassandra stress stop --all

    echo "=== Verifying stress jobs are deleted ==="
    easy-db-lab cassandra stress status
}

step_spark_submit() {
    if [ "$ENABLE_SPARK" != true ]; then
        echo "=== Skipping Spark job submission (use --spark to enable) ==="
        return 0
    fi
    echo "=== Submitting Spark job to EMR ==="
    easy-db-lab spark submit \
      --jar "$PROJECT_ROOT/spark-connector-test1/build/libs/spark-connector-test1-12.jar" \
      --main-class com.rustyrazorblade.easydblab.spark.KeyValuePrefixCount \
      --args "$(easy-db-lab ip db0 --private)" \
      --wait
}

step_spark_status() {
    if [ "$ENABLE_SPARK" != true ]; then
        echo "=== Skipping Spark status check (use --spark to enable) ==="
        return 0
    fi
    echo "=== Listing Spark jobs ==="
    easy-db-lab spark jobs

    echo "=== Checking Spark job status (automatically downloads logs) ==="
    easy-db-lab spark status

    echo "=== Downloading all EMR logs (standalone command) ==="
    easy-db-lab spark logs
}

step_clickhouse_start() {
    if [ "$ENABLE_CLICKHOUSE" != true ]; then
        echo "=== Skipping ClickHouse deployment (use --clickhouse to enable) ==="
        return 0
    fi
    echo "=== Deploying ClickHouse cluster ==="
    easy-db-lab clickhouse start

    echo "=== Checking ClickHouse cluster status ==="
    easy-db-lab clickhouse status

    echo "=== Waiting for ClickHouse pods to be ready ==="
    kubectl wait --for=condition=Ready pods --all -n clickhouse --timeout=300s

    echo "=== Verifying ClickHouse pods ==="
    kubectl get pods -n clickhouse
}

step_clickhouse_test() {
    if [ "$ENABLE_CLICKHOUSE" != true ]; then
        echo "=== Skipping ClickHouse test (use --clickhouse to enable) ==="
        return 0
    fi
    echo "=== Testing ClickHouse connectivity ==="

    clickhouse-query "SELECT version()"

    clickhouse-query <<'EOF'
CREATE OR REPLACE TABLE test (
    id UInt64,
    updated_at DateTime DEFAULT now(),
    updated_at_date Date DEFAULT toDate(updated_at)
) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/default/test', '{replica}')
ORDER BY id
SETTINGS storage_policy = 's3_main'
EOF

    clickhouse-query "INSERT INTO test (id) VALUES (1)"
}

step_clickhouse_stop() {
    if [ "$ENABLE_CLICKHOUSE" != true ]; then
        echo "=== Skipping ClickHouse stop (use --clickhouse to enable) ==="
        return 0
    fi
    echo "=== Stopping ClickHouse cluster ==="
    easy-db-lab clickhouse stop --force

    echo "=== Verifying ClickHouse namespace is deleted ==="
    local timeout=60
    local elapsed=0
    while [ $elapsed -lt $timeout ]; do
      if ! kubectl get namespace clickhouse &>/dev/null; then
        echo "ClickHouse namespace successfully deleted"
        return 0
      fi
      echo "Waiting for ClickHouse namespace to be deleted... ($elapsed/$timeout seconds)"
      sleep 5
      elapsed=$((elapsed + 5))
    done
}

step_opensearch_start() {
    if [ "$ENABLE_OPENSEARCH" != true ]; then
        echo "=== Skipping OpenSearch deployment (use --opensearch to enable) ==="
        return 0
    fi
    echo "=== Deploying OpenSearch domain (this takes 10-30 minutes) ==="
    easy-db-lab opensearch start --wait

    echo "=== Checking OpenSearch domain status ==="

    # should be ready
    easy-db-lab opensearch status
}

step_opensearch_test() {
    if [ "$ENABLE_OPENSEARCH" != true ]; then
        echo "=== Skipping OpenSearch test (use --opensearch to enable) ==="
        return 0
    fi
    echo "=== Testing OpenSearch connectivity ==="

    # Get endpoint using --endpoint flag
    local endpoint=$(easy-db-lab opensearch status --endpoint)
    if [ -z "$endpoint" ]; then
        echo "ERROR: Could not get OpenSearch endpoint"
        return 1
    fi

    echo "=== OpenSearch endpoint: $endpoint ==="

    # Test cluster health via control node
    echo "=== Testing cluster health ==="
    ssh control0 "curl -s -k https://${endpoint}/_cluster/health" | jq .

    # Create test index
    echo "=== Creating test index ==="
    ssh control0 "curl -s -k -X PUT https://${endpoint}/test-index"

    # Insert test document
    echo "=== Inserting test document ==="
    ssh control0 "curl -s -k -X POST https://${endpoint}/test-index/_doc/1 -H 'Content-Type: application/json' -d '{\"message\": \"hello from e2e test\"}'"

    # Verify document
    echo "=== Verifying test document ==="
    ssh control0 "curl -s -k https://${endpoint}/test-index/_doc/1" | jq .
}

step_opensearch_stop() {
    if [ "$ENABLE_OPENSEARCH" != true ]; then
        echo "=== Skipping OpenSearch stop (use --opensearch to enable) ==="
        return 0
    fi
    echo "=== Stopping OpenSearch domain ==="
    easy-db-lab opensearch stop --force
}

step_test_observability() {
    echo "=== Testing VictoriaMetrics and VictoriaLogs ==="

    # Wait for VictoriaMetrics to be ready
    echo "=== Waiting for VictoriaMetrics pod to be ready ==="
    kubectl wait --for=condition=Ready pod -l app.kubernetes.io/name=victoriametrics --timeout=120s

    # Wait for VictoriaLogs to be ready
    echo "=== Waiting for VictoriaLogs pod to be ready ==="
    kubectl wait --for=condition=Ready pod -l app.kubernetes.io/name=victorialogs --timeout=120s

    # Test VictoriaMetrics health endpoint
    echo "=== Testing VictoriaMetrics health ==="
    local vm_health=$(ssh control0 "curl -s http://localhost:8428/health")
    echo "VictoriaMetrics health: $vm_health"

    # Test VictoriaLogs health endpoint
    echo "=== Testing VictoriaLogs health ==="
    local vl_health=$(ssh control0 "curl -s http://localhost:9428/health")
    echo "VictoriaLogs health: $vl_health"

    # Query VictoriaMetrics for metrics (should have some metrics from OTel)
    echo "=== Querying VictoriaMetrics for metrics ==="
    local metrics_count=$(ssh control0 "curl -s 'http://localhost:8428/api/v1/label/__name__/values' | jq '.data | length'")
    echo "Number of metric names in VictoriaMetrics: $metrics_count"
    if [ "$metrics_count" -lt 1 ]; then
        echo "WARNING: No metrics found in VictoriaMetrics yet (may need more time for OTel to send data)"
    fi

    # Query VictoriaLogs to check it's accepting connections
    echo "=== Testing VictoriaLogs query endpoint ==="
    local vl_query=$(ssh control0 "curl -s -o /dev/null -w '%{http_code}' 'http://localhost:9428/select/logsql/query?query=*'")
    echo "VictoriaLogs query endpoint response code: $vl_query"
    if [ "$vl_query" != "200" ]; then
        echo "WARNING: VictoriaLogs query endpoint returned unexpected status: $vl_query"
    fi

    # Test Grafana is up and datasources are configured
    echo "=== Testing Grafana health ==="
    local grafana_health=$(ssh control0 "curl -s http://localhost:3000/api/health | jq -r '.database'")
    echo "Grafana database status: $grafana_health"

    echo "=== Testing Grafana datasources ==="
    local datasources=$(ssh control0 "curl -s http://localhost:3000/api/datasources | jq -r '.[].name'")
    echo "Configured datasources:"
    echo "$datasources"

    # Verify VictoriaMetrics datasource exists
    if echo "$datasources" | grep -q "VictoriaMetrics"; then
        echo "VictoriaMetrics datasource: OK"
    else
        echo "ERROR: VictoriaMetrics datasource not found!"
        return 1
    fi

    # Verify VictoriaLogs datasource exists
    if echo "$datasources" | grep -q "VictoriaLogs"; then
        echo "VictoriaLogs datasource: OK"
    else
        echo "ERROR: VictoriaLogs datasource not found!"
        return 1
    fi

    echo "=== Observability stack test completed ==="
}

step_teardown() {
    echo "=== Tearing down cluster ==="
    easy-db-lab down --yes

    echo "=== End-to-end test completed successfully ==="
}

# ============================================================================
# Step Registry and Runner
# ============================================================================

# Steps that run from project root (before cd to TEST_WORKDIR)
STEPS_PROJECT_ROOT=(
    "step_build_project:Build project"
    "step_check_version:Check version"
    "step_build_image:Build packer image"
)

# Steps that run from TEST_WORKDIR
STEPS_WORKDIR=(
    "step_set_policies:Set IAM policies"
    "step_init_cluster:Initialize cluster"
    "step_setup_kubectl:Setup kubectl"
    "step_wait_k3s_ready:Wait for K3s"
    "step_verify_k3s:Verify K3s cluster"
    "step_registry_push_pull:Test registry push/pull"
    "step_list_hosts:List hosts"
    "step_setup_cassandra:Setup Cassandra"
    "step_cassandra_start_stop:Cassandra start/stop cycle"
    "step_test_ssh_nodetool:Test SSH and nodetool"
    "step_check_sidecar:Check Sidecar"
    "step_test_exec:Test exec command"
    "step_stress_test:Run stress test"
    "step_stress_k8s:Run stress K8s test"
    "step_spark_submit:Submit Spark job"
    "step_spark_status:Check Spark status"
    "step_clickhouse_start:Start ClickHouse"
    "step_clickhouse_test:Test ClickHouse"
    "step_clickhouse_stop:Stop ClickHouse"
    "step_opensearch_start:Start OpenSearch"
    "step_opensearch_test:Test OpenSearch"
    "step_opensearch_stop:Stop OpenSearch"
    "step_test_observability:Test observability stack"
    "step_teardown:Teardown cluster"
)

# Combined steps for resume
ALL_STEPS=("${STEPS_PROJECT_ROOT[@]}" "${STEPS_WORKDIR[@]}")
PROJECT_ROOT_STEP_COUNT=${#STEPS_PROJECT_ROOT[@]}

list_steps() {
    echo "Available steps:"
    echo ""
    local total_steps=${#ALL_STEPS[@]}
    for ((i=0; i<total_steps; i++)); do
        local step_entry="${ALL_STEPS[$i]}"
        local step_name="${step_entry#*:}"
        printf "  %2d) %s\n" "$((i+1))" "$step_name"
    done
}

is_breakpoint() {
    local step_num=$1
    if [ -z "$BREAKPOINTS" ]; then
        return 1
    fi
    IFS=',' read -ra BP_ARRAY <<< "$BREAKPOINTS"
    for bp in "${BP_ARRAY[@]}"; do
        if [ "$bp" = "$step_num" ]; then
            return 0
        fi
    done
    return 1
}

run_from_step() {
    local start_step=${1:-0}
    local total_steps=${#ALL_STEPS[@]}
    local end_step=${2:-$total_steps}  # Optional end step (exclusive), defaults to all

    for ((i=start_step; i<end_step; i++)); do
        CURRENT_STEP=$i
        local step_entry="${ALL_STEPS[$i]}"
        local step_func="${step_entry%%:*}"
        local step_name="${step_entry#*:}"
        CURRENT_STEP_NAME="$step_name"

        echo ""
        echo "=========================================="
        echo "Step $((i+1))/$total_steps: $step_name"
        echo "=========================================="

        # Check for breakpoint
        if is_breakpoint "$((i+1))"; then
            echo ""
            echo ">>> BREAKPOINT at step $((i+1)): $step_name"
            read -p "Press Enter to continue..."
            echo ""
        fi

        # Determine which directory to run in and execute step
        # Disable errexit temporarily for controlled error handling
        set +e
        if [ $i -lt $PROJECT_ROOT_STEP_COUNT ]; then
            pushd "$PROJECT_ROOT" > /dev/null
            $step_func
            local result=$?
            popd > /dev/null
        else
            pushd "$TEST_WORKDIR" > /dev/null
            # Only source env.sh for steps after step_setup_kubectl (index 5)
            # Earlier steps either don't need it or source it themselves
            local setup_kubectl_index=$((PROJECT_ROOT_STEP_COUNT + 2))  # step_setup_kubectl position
            if [ $i -gt $setup_kubectl_index ] && [ -f env.sh ]; then
                source env.sh
            fi
            $step_func
            local result=$?
            popd > /dev/null
        fi
        set -e
        if [ $result -ne 0 ]; then return 1; fi
    done

    return 0
}

# Export variables for use in subshells (e.g., zsh session)
export PROJECT_ROOT TEST_WORKDIR

# ============================================================================
# Cleanup Function
# ============================================================================

cleanup() {
    local exit_code=$?

    # Success case - exit cleanly
    if [ "$EXIT_OK" = true ]; then
        echo ""
        echo "=== All tests passed successfully ==="
        exit 0
    fi

    if [ "$WAIT_BEFORE_TEARDOWN" != true ]; then
        while true; do
            echo ""
            echo "=== Test work directory: $TEST_WORKDIR ==="
            if [ -n "$CURRENT_STEP_NAME" ]; then
                echo "Failed at step $((CURRENT_STEP+1)): $CURRENT_STEP_NAME"
            fi
            echo ""
            echo "What would you like to do?"
            echo "  1) Retry from failed step (resume test)"
            echo "  2) Start a shell session in the directory"
            echo "  3) Tear down environment (easy-db-lab down --yes)"
            echo "  4) Exit"
            echo ""
            read -p "Choose [1-4]: " -n 1 -r choice
            echo
            case $choice in
                1)
                    if [ -n "$CURRENT_STEP" ]; then
                        echo "=== Resuming from step $((CURRENT_STEP+1)): $CURRENT_STEP_NAME ==="
                        if run_from_step "$CURRENT_STEP"; then
                            echo "=== Test completed successfully ==="
                            exit_code=0
                            break
                        else
                            echo "=== Step failed again ==="
                        fi
                    else
                        echo "No step to retry."
                    fi
                    ;;
                2)
                    echo "=== Starting shell session in $TEST_WORKDIR ==="
                    echo "Available commands:"
                    echo "  easy-db-lab  - Run easy-db-lab commands"
                    echo "  rebuild      - Rebuild the project (shadowJar + installDist)"
                    echo "  rerun        - Rebuild and resume from failed step"
                    echo "Type 'exit' to return to cleanup menu"
                    echo ""
                    (
                        cd "$TEST_WORKDIR"

                        # Create temp zsh config directory
                        TEMP_ZDOTDIR=$(mktemp -d)

                        # Create custom .zshrc with our functions
                        cat > "$TEMP_ZDOTDIR/.zshrc" << ZSHRC_EOF
# Easy DB Lab shell session

# easy-db-lab is available via PATH (set by parent script)

# Rebuild function - runs gradle in project root
rebuild() {
    echo "=== Rebuilding project ==="
    (cd "\$PROJECT_ROOT" && ./gradlew shadowJar installDist)
    echo "=== Rebuild complete ==="
}

# Rerun function - rebuild and resume from failed step
rerun() {
    echo "=== Rebuilding project ==="
    (cd "\$PROJECT_ROOT" && ./gradlew shadowJar installDist)
    if [ \$? -ne 0 ]; then
        echo "=== Rebuild failed ==="
        return 1
    fi
    echo "=== Rebuild complete ==="
    echo "=== Resuming from step $((CURRENT_STEP+1)): $CURRENT_STEP_NAME ==="
    echo "NOTE: For full resume with proper environment, exit shell and choose option 1"
}

# Source env.sh if it exists in current directory
if [ -f env.sh ]; then
    source env.sh
fi

# Source user's real zshrc for comfort (prompt, etc.) but ignore errors
[ -f ~/.zshrc ] && source ~/.zshrc 2>/dev/null || true
ZSHRC_EOF

                        # Export variables for the new shell
                        export PROJECT_ROOT
                        export ZDOTDIR="$TEMP_ZDOTDIR"

                        # Start zsh with our custom config
                        exec zsh
                    )
                    # Loop back to menu after shell exits
                    ;;
                3)
                    echo "=== Tearing down environment ==="
                    (
                        cd "$TEST_WORKDIR"
                        if [ -f env.sh ]; then
                            source env.sh
                        fi
                        easy-db-lab down --yes
                    )
                    echo "=== Environment torn down ==="
                    # Loop back to menu for directory cleanup
                    ;;
                4)
                    echo "=== Exiting ==="
                    break
                    ;;
                *)
                    echo "Invalid choice. Please enter 1, 2, 3, or 4."
                    ;;
            esac
        done
    fi
    exit $exit_code
}
trap cleanup EXIT

# ============================================================================
# Main Execution
# ============================================================================

# Handle --list-steps flag
if [ "$LIST_STEPS" = true ]; then
    list_steps
    EXIT_OK=true
    exit 0
fi

# Change to work directory
cd "$TEST_WORKDIR"
echo "=== Work directory: $(pwd) ==="

# Handle --wait flag for inspection before teardown
if [ "$WAIT_BEFORE_TEARDOWN" = true ]; then
    # Run all steps except teardown (last step)
    TOTAL_STEPS=${#ALL_STEPS[@]}
    LAST_STEP=$((TOTAL_STEPS - 1))  # Teardown is the last step
    run_from_step 0 $LAST_STEP || exit 1

    # Prompt user before teardown
    echo ""
    echo "=== Cluster is ready for inspection ==="
    echo "The cluster is now running and ready to inspect."
    echo "Work directory: $TEST_WORKDIR"
    echo "You can:"
    echo "  - Run: kubectl get nodes"
    echo "  - Run: kubectl get pods -A"
    echo "  - SSH to nodes using the aliases from env.sh"
    echo "  - Test Cassandra connectivity"
    echo ""
    read -p "Press Enter to tear down the cluster and complete the test..."
    echo ""

    # Now run teardown
    step_teardown
    EXIT_OK=true
else
    # Run all steps
    run_from_step 0
    EXIT_OK=true
fi
